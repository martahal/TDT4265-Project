{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jesperpaulsen/.conda/envs/tdt4265/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jesperpaulsen/.conda/envs/tdt4265/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jesperpaulsen/.conda/envs/tdt4265/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jesperpaulsen/.conda/envs/tdt4265/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jesperpaulsen/.conda/envs/tdt4265/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jesperpaulsen/.conda/envs/tdt4265/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%autoreload \n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "import torch\n",
    "from ssd.engine.inference import do_evaluation\n",
    "from ssd.config.defaults import cfg\n",
    "from ssd.utils.logger import setup_logger\n",
    "from train import start_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-19 14:58:50,404 SSD INFO: Loaded configuration file configs/train_rdd2020_server_experimental.yaml\n",
      "2021-04-19 14:58:50,406 SSD INFO: \n",
      "MODEL:\n",
      "    NUM_CLASSES: 5\n",
      "    THRESHOLD: 0.5\n",
      "    BACKBONE:\n",
      "        NAME: 'res_net'\n",
      "        PRETRAINED: True\n",
      "        OUT_CHANNELS: [256, 512, 256, 256, 128, 128]\n",
      "        INPUT_CHANNELS: 3\n",
      "    PRIORS:\n",
      "        MIN_SIZES: [[15, 15], [45, 45], [111, 111], [162, 162], [213, 213], [264, 264]]\n",
      "        MAX_SIZES: [[45, 45], [111, 111], [162, 162], [213, 213], [264, 264], [315, 315]]\n",
      "        FEATURE_MAPS: [[63, 38], [32, 19], [16, 10], [8, 5], [4, 3], [2, 1]]\n",
      "        STRIDES: [[8, 8], [16, 16], [32, 32], [64, 64], [100, 100], [300, 300]]\n",
      "\n",
      "INPUT:\n",
      "    IMAGE_SIZE: [500, 300]\n",
      "DATASETS:\n",
      "    TRAIN: (\"rdd2020_train\",)\n",
      "    TEST: (\"rdd2020_val\", )\n",
      "SOLVER:\n",
      "    MAX_ITER: 120000\n",
      "    GAMMA: 0.1\n",
      "    BATCH_SIZE: 16\n",
      "    LR: 1e-3\n",
      "OUTPUT_DIR: 'outputs/rdd2020_experimentals'\n",
      "DATASET_DIR: \"datasets\"\n",
      "2021-04-19 14:58:50,407 SSD INFO: Running with config:\n",
      "DATASETS:\n",
      "  TEST: ('rdd2020_val',)\n",
      "  TRAIN: ('rdd2020_train',)\n",
      "DATASET_DIR: datasets\n",
      "DATA_LOADER:\n",
      "  NUM_WORKERS: 4\n",
      "  PIN_MEMORY: True\n",
      "EVAL_STEP: 500\n",
      "INPUT:\n",
      "  IMAGE_SIZE: [500, 300]\n",
      "  PIXEL_MEAN: [123.675, 116.28, 103.53]\n",
      "  PIXEL_STD: [1, 1, 1]\n",
      "LOG_STEP: 10\n",
      "MODEL:\n",
      "  BACKBONE:\n",
      "    INPUT_CHANNELS: 3\n",
      "    NAME: res_net\n",
      "    OUT_CHANNELS: (256, 512, 256, 256, 128, 128)\n",
      "    PRETRAINED: True\n",
      "  CENTER_VARIANCE: 0.1\n",
      "  NEG_POS_RATIO: 3\n",
      "  NUM_CLASSES: 5\n",
      "  PRIORS:\n",
      "    ASPECT_RATIOS: [[2], [2, 3], [2, 3], [2, 3], [2], [2]]\n",
      "    BOXES_PER_LOCATION: [4, 6, 6, 6, 4, 4]\n",
      "    CLIP: True\n",
      "    FEATURE_MAPS: [[63, 38], [32, 19], [16, 10], [8, 5], [4, 3], [2, 1]]\n",
      "    MAX_SIZES: [[45, 45], [111, 111], [162, 162], [213, 213], [264, 264], [315, 315]]\n",
      "    MIN_SIZES: [[15, 15], [45, 45], [111, 111], [162, 162], [213, 213], [264, 264]]\n",
      "    STRIDES: [[8, 8], [16, 16], [32, 32], [64, 64], [100, 100], [300, 300]]\n",
      "  SIZE_VARIANCE: 0.2\n",
      "  THRESHOLD: 0.5\n",
      "MODEL_SAVE_STEP: 500\n",
      "OUTPUT_DIR: outputs/rdd2020_experimentals\n",
      "SOLVER:\n",
      "  BATCH_SIZE: 16\n",
      "  GAMMA: 0.1\n",
      "  LR: 0.001\n",
      "  MAX_ITER: 120000\n",
      "  MOMENTUM: 0.9\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "TEST:\n",
      "  BATCH_SIZE: 10\n",
      "  CONFIDENCE_THRESHOLD: 0.01\n",
      "  MAX_PER_CLASS: -1\n",
      "  MAX_PER_IMAGE: 100\n",
      "  NMS_THRESHOLD: 0.45\n"
     ]
    }
   ],
   "source": [
    "#config_file = \"configs/vgg_ssd300_voc0712_tdt4265_server.yaml\"\n",
    "#config_file = \"configs/mnist_tdt4265_server_experimental.yaml\"\n",
    "# config_file = \"configs/train_rdd2020_server.yaml\"\n",
    "config_file = \"configs/train_rdd2020_server_experimental.yaml\"\n",
    "cfg.merge_from_file(config_file)\n",
    "cfg.freeze()\n",
    "output_dir = pathlib.Path(cfg.OUTPUT_DIR)\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "logger = setup_logger(\"SSD\", output_dir)\n",
    "\n",
    "logger.info(\"Loaded configuration file {}\".format(config_file))\n",
    "with open(config_file, \"r\") as cf:\n",
    "    config_str = \"\\n\" + cf.read()\n",
    "    logger.info(config_str)\n",
    "logger.info(\"Running with config:\\n{}\".format(cfg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jesperpaulsen/school/TDT4265-Project/assignment4/SSD\n",
      "Detector initialized. Total Number of params:  18.26M\n",
      "Backbone number of parameters: 17.59M\n",
      "SSD Head number of parameters: 663.8K\n",
      "2021-04-19 15:00:04,277 SSD.trainer INFO: No checkpoint found.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets/RDD2020_filtered/ImageSets/train.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-9963cf725677>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mget_ipython\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msystem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'pwd'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstart_train\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcfg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/school/TDT4265-Project/assignment4/SSD/train.py\u001B[0m in \u001B[0;36mstart_train\u001B[0;34m(cfg)\u001B[0m\n\u001B[1;32m     68\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m     \u001B[0mmax_iter\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcfg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSOLVER\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mMAX_ITER\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 70\u001B[0;31m     \u001B[0mtrain_loader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmake_data_loader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcfg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_train\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_iter\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmax_iter\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstart_iter\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0marguments\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'iteration'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     71\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     72\u001B[0m     model = do_train(\n",
      "\u001B[0;32m~/school/TDT4265-Project/assignment4/SSD/ssd/data/build.py\u001B[0m in \u001B[0;36mmake_data_loader\u001B[0;34m(cfg, is_train, max_iter, start_iter)\u001B[0m\n\u001B[1;32m     34\u001B[0m         \u001B[0mcfg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDATASET_DIR\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     35\u001B[0m         \u001B[0mdataset_list\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtransform\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtrain_transform\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 36\u001B[0;31m         target_transform=target_transform, is_train=is_train)\n\u001B[0m\u001B[1;32m     37\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     38\u001B[0m     \u001B[0mshuffle\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mis_train\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/school/TDT4265-Project/assignment4/SSD/ssd/data/datasets/__init__.py\u001B[0m in \u001B[0;36mbuild_dataset\u001B[0;34m(base_path, dataset_list, transform, target_transform, is_train)\u001B[0m\n\u001B[1;32m     24\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mfactory\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mVOCDataset\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m             \u001B[0margs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'keep_difficult'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mis_train\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 26\u001B[0;31m         \u001B[0mdataset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfactory\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     27\u001B[0m         \u001B[0mdatasets\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m     \u001B[0;31m# for testing, return a list of datasets\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/school/TDT4265-Project/assignment4/SSD/ssd/data/datasets/rdd2020.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, data_dir, split, transform, target_transform)\u001B[0m\n\u001B[1;32m     26\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtarget_transform\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtarget_transform\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m         \u001B[0mimage_sets_file\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata_dir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"ImageSets\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34mf\"{self.split}.txt\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 28\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimage_ids\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mRDDDataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_read_image_ids\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage_sets_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     29\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclass_dict\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0mclass_name\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclass_name\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclass_names\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     30\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Dataset loaded. Subset: {split}, number of images: {len(self)}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/school/TDT4265-Project/assignment4/SSD/ssd/data/datasets/rdd2020.py\u001B[0m in \u001B[0;36m_read_image_ids\u001B[0;34m(image_sets_file)\u001B[0m\n\u001B[1;32m     54\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_read_image_ids\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage_sets_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     55\u001B[0m         \u001B[0mids\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 56\u001B[0;31m         \u001B[0;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage_sets_file\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     57\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mline\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     58\u001B[0m                 \u001B[0mids\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrstrip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'datasets/RDD2020_filtered/ImageSets/train.txt'"
     ]
    }
   ],
   "source": [
    "!pwd \n",
    "model = start_train(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-15 10:20:59,235 SSD INFO: Start evaluating...\n",
      "2021-04-15 10:21:01,146 SSD.inference INFO: Evaluating mnist_detection_val dataset(1000 images):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 24.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-15 10:21:06,107 SSD.inference INFO: mAP: 0.8952\n",
      "0               : 0.9038\n",
      "1               : 0.8619\n",
      "2               : 0.8991\n",
      "3               : 0.9034\n",
      "4               : 0.9012\n",
      "5               : 0.9012\n",
      "6               : 0.9021\n",
      "7               : 0.8900\n",
      "8               : 0.9006\n",
      "9               : 0.8886\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'metrics': {'mAP': 0.8952024131918288,\n",
       "   '0': 0.9038319683421214,\n",
       "   '1': 0.8619123396332643,\n",
       "   '2': 0.8991184457164805,\n",
       "   '3': 0.9034108127494757,\n",
       "   '4': 0.9012078430736787,\n",
       "   '5': 0.9011639146270728,\n",
       "   '6': 0.9021376905405668,\n",
       "   '7': 0.8900135604682246,\n",
       "   '8': 0.9006312166832495,\n",
       "   '9': 0.8885963400841522}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.info('Start evaluating...')\n",
    "torch.cuda.empty_cache()  # speed up evaluating after training finished\n",
    "do_evaluation(cfg, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}